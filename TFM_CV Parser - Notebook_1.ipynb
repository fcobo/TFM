{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CV Parser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Introducción"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este primer notebook tiene como objetivo acceder a un directorio para identificar aquellos archivos correspondientes a Curriculums, leerlos y guardar el texto en un formato semistructurado como JSON a través de un repositorio de MongoDB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Pasos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Obtención de la ruta de cada CV\n",
    "2. Lectura PDFs - Itext\n",
    "3. Identificación del lenguaje\n",
    "4. Exportación a JSON - MongoDB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Código fuente"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Obtención de la ruta de cada CV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El repositorio inicial se compone de tantas carpetas como usuarios con CV a analizar. Además, de cada usuario, se disponen de diversos ficheros, desde el CV, un extracto de notas hasta la fotocopia de algún documento personal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "\n",
    "cvsDirectory = r\"C:\\Users\\fernando.coboaguiler\\Desktop\\TFM\\Codigo\\CVs_PDF\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como existen diversos archivos e incluso diversos formatos de texto, se va a simplificar la solución buscando sólo aquellos documentos pdf que contengan una de las siguientes palabras clave: [cv, curriculum, vitae]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "Keywords = [\"cv\",\"curriculum\",\"vitae\"]\n",
    "PDFs = []\n",
    "NonPDFs = 0\n",
    "\n",
    "for folder in os.listdir(cvsDirectory):\n",
    "    for f in glob.glob(cvsDirectory + \"\\\\\" + folder  + \"\\\\*\"):   \n",
    "        if f[-4:].lower() == \".pdf\":\n",
    "            if any([keyword for keyword in Keywords if keyword in os.path.basename(f).lower()]):\n",
    "                PDFs.append(cvsDirectory + \"\\\\\" + folder + \"\\\\\" + os.path.basename(f).lower())\n",
    "        else:\n",
    "            NonPDFs += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El número total de PDFs con los que se va a trabajar es: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4613"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(PDFs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Lectura PDFs - Itext"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez obtenido el path de cada CV, se va a proceder a su lectura utilizando la librería iText en su versión .Net (iTextSharp). Para poder invocar los métodos desarrollados en C#, se va a hacer uso de la librería CLR que permite la integración de librerías .NET en Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<System.Reflection.RuntimeAssembly at 0x540e160>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import clr\n",
    "clr.AddReference(r'C:\\Users\\fernando.coboaguiler\\Desktop\\TFM\\Codigo\\Itext\\Itext-CVs.dll')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La librería está desarrollada bajo el namespace \"wavespace\", siendo la clase denominada \"Pdf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wavespace import Pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Al igual que ser haría en .Net, se debe crear un objeto de la clase \"Pdf\" y, en este caso, configurar el encoding para poder leer los pdfs correctamente, utilizando la función \"setEncoding\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdfParser = Pdf()\n",
    "pdfParser.setEncoding()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez el objeto está cargado en memoria, se puede invocar su método principal, para la lectura del PDF. Para la lectura, cada PDF se va a guardar utilizando un array de Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "contents = []\n",
    "types = []\n",
    "files = []\n",
    "pages = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por cada PDF:\n",
    "\n",
    "- Se intenta abrir\n",
    "- Se calcula el número de páginas\n",
    "- Se lee cada página y se acumula el resultado en una variable de texto\n",
    "  \n",
    "Dos tipos de erroes son contemplados:\n",
    "\n",
    "- El PDF no se puede abrir (está corrupto)\n",
    "- Tras leer un PDF, no se obtiene nada. Para estos casos, vamos a suponer que es un PDF en formato imagen, ilegible por iText, y cuya lectura debe ser efectuada utilizando otra tecnología"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error:C:\\Users\\fernando.coboaguiler\\Desktop\\TFM\\Codigo\\CVs_PDF\\Carmen Diez Guijarro\\carmen díez's cv.pdf\n",
      "Error:C:\\Users\\fernando.coboaguiler\\Desktop\\TFM\\Codigo\\CVs_PDF\\Diana Morejón Hernandez\\cv diana morejón hernández.pdf\n",
      "Error:C:\\Users\\fernando.coboaguiler\\Desktop\\TFM\\Codigo\\CVs_PDF\\Diego Kreisler\\cv - diego kreisler .pdf\n",
      "Error:C:\\Users\\fernando.coboaguiler\\Desktop\\TFM\\Codigo\\CVs_PDF\\Diego Navas Arroyo\\cv_diego_navas_actualizado.pdf\n",
      "Error:C:\\Users\\fernando.coboaguiler\\Desktop\\TFM\\Codigo\\CVs_PDF\\Fernando Alvarez de Rivera\\my cv7 (box).pdf\n",
      "Error:C:\\Users\\fernando.coboaguiler\\Desktop\\TFM\\Codigo\\CVs_PDF\\Fernando Izquierdo\\fernando izquierdo blanco cv inglés.pdf\n",
      "Error:C:\\Users\\fernando.coboaguiler\\Desktop\\TFM\\Codigo\\CVs_PDF\\Fernando Izquierdo\\fernando izquierdo cv español.pdf\n",
      "Error:C:\\Users\\fernando.coboaguiler\\Desktop\\TFM\\Codigo\\CVs_PDF\\Gonzalo Puig\\cv gonzalo puig.pdf\n",
      "Error:C:\\Users\\fernando.coboaguiler\\Desktop\\TFM\\Codigo\\CVs_PDF\\Juan Salmador\\cv+expediente.pdf\n",
      "Error:C:\\Users\\fernando.coboaguiler\\Desktop\\TFM\\Codigo\\CVs_PDF\\Maria Alonso-Martirena\\cv maría alonso-martirena.pdf\n",
      "Error:C:\\Users\\fernando.coboaguiler\\Desktop\\TFM\\Codigo\\CVs_PDF\\Maria Teresa Espinosa\\cv maria teresa espinosa.pdf\n",
      "Error:C:\\Users\\fernando.coboaguiler\\Desktop\\TFM\\Codigo\\CVs_PDF\\Patricia Martinez\\cv+exp.pdf\n",
      "Error:C:\\Users\\fernando.coboaguiler\\Desktop\\TFM\\Codigo\\CVs_PDF\\Romualdo Mora-Figueroa\\cv romualdo mora-figueroa madariaga (oct 2017).pdf\n",
      "243.95295333862305\n"
     ]
    }
   ],
   "source": [
    "for file in PDFs:\n",
    "    \n",
    "    if pdfParser.openPDF(file):\n",
    "        \n",
    "        content_ = \"\"\n",
    "        pages_ = pdfParser.getNumberPages()+1\n",
    "        for i in range(1,pages_):\n",
    "            content_ += pdfParser.readPDFbyPage(i)\n",
    "        \n",
    "        pages.append(pages_)\n",
    "        contents.append(content_)\n",
    "        files.append(file)\n",
    "        \n",
    "        if content_ != \"\":\n",
    "            types.append(\"Text\")\n",
    "        else:\n",
    "            types.append(\"Image\")\n",
    "                \n",
    "        pdfParser.closePDF()\n",
    "    else:\n",
    "        print(\"Error:\" + str(file))    \n",
    "\n",
    "CVs_Dataframe = pd.DataFrame()\n",
    "\n",
    "CVs_Dataframe['CV'] = contents\n",
    "CVs_Dataframe['File'] = files\n",
    "CVs_Dataframe['Type'] = types\n",
    "CVs_Dataframe['Pages'] = pages\n",
    "    \n",
    "print(time.time()-start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "TotalCVs = len(CVs_Dataframe)\n",
    "TotalCVs_Text = len(CVs_Dataframe[CVs_Dataframe.Type == \"Text\"])\n",
    "TotalCVs_Image = len(CVs_Dataframe[CVs_Dataframe.Type == \"Image\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total PDFs - Text format: 4498 -> 97.78260869565217%\n",
      "Total PDFs - Image format: 102 -> 2.2173913043478257%\n"
     ]
    }
   ],
   "source": [
    "print(\"Total PDFs - Text format: \" + str(TotalCVs_Text) + \" -> \" + str(TotalCVs_Text/TotalCVs*100) + \"%\")\n",
    "print(\"Total PDFs - Image format: \" + str(TotalCVs_Image) + \" -> \" + str(TotalCVs_Image/TotalCVs*100) + \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Identificación del lenguaje"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como ya se predijo, los CVs pueden venir en distintos formatos e incluso en distintos idiomas. Es por ello, que se requiere de una clasificación inicial de dichos CVs en base al idioma, con el objetivo de descartar aquellos cuyo idioma no sea el castellano.\n",
    "\n",
    "Para la detección del idoma se van a usar dos técnicas, una a través de NLTK y el conteo de stop words de diversos idiomas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "\n",
    "def detect_language(text):\n",
    "    \n",
    "    languages_ratios = {}\n",
    "    tokens = [word.lower() for word in nltk.word_tokenize(text)]\n",
    "    \n",
    "    for language in nltk.corpus.stopwords.fileids():\n",
    "        stopwords_set = set(nltk.corpus.stopwords.words(language))\n",
    "        words_set = set(tokens)\n",
    "        common_elements = words_set.intersection(stopwords_set)\n",
    "\n",
    "        languages_ratios[language] = len(common_elements)\n",
    "    \n",
    "    most_rated_language = max(languages_ratios, key=languages_ratios.get)\n",
    "    return most_rated_language"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y una segunda utilizando la librería langdetect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langdetect import detect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cuando ambos algoritmos coinciden, vamos a considerar que el idioma ha sido correctamente detectado, de lo contrario, lo consideraremos indefinido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "389.433274269104\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "languages = []\n",
    "\n",
    "for index, row in CVs_Dataframe.iterrows():\n",
    "    if isinstance(row['CV'], str):\n",
    "        text = row['CV']\n",
    "    else:\n",
    "        text = row['CV'].decode(\"utf-8\")\n",
    "\n",
    "    language1 = detect_language(text)\n",
    "    \n",
    "    try:\n",
    "        language2 = detect(text)\n",
    "    except:\n",
    "        language2 = \"\"\n",
    "\n",
    "    if language1 == \"spanish\" and language2 == \"es\":\n",
    "        languages.append(\"Spanish\")\n",
    "    elif language1 == \"english\" and language2 == \"en\":\n",
    "        languages.append(\"English\")\n",
    "    else:\n",
    "        languages.append(\"Undefined\")           \n",
    "\n",
    "CVs_Dataframe['Language'] = languages\n",
    "print(time.time()-start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "TotalCVs = len(CVs_Dataframe)\n",
    "TotalCVs_Spanish = len(CVs_Dataframe[CVs_Dataframe.Language == \"Spanish\"])\n",
    "TotalCVs_English = len(CVs_Dataframe[CVs_Dataframe.Language == \"English\"])\n",
    "TotalCVs_Undefined = len(CVs_Dataframe[CVs_Dataframe.Language == \"Undefined\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total PDFs - Spanish: 3638 -> 79.08695652173913%\n",
      "Total PDFs - English: 751 -> 16.326086956521742%\n",
      "Total PDFs - Undefined: 211 -> 4.586956521739131%\n"
     ]
    }
   ],
   "source": [
    "print(\"Total PDFs - Spanish: \" + str(TotalCVs_Spanish) + \" -> \" + str(TotalCVs_Spanish/TotalCVs*100) + \"%\")\n",
    "print(\"Total PDFs - English: \" + str(TotalCVs_English) + \" -> \" + str(TotalCVs_English/TotalCVs*100) + \"%\")\n",
    "print(\"Total PDFs - Undefined: \" + str(TotalCVs_Undefined) + \" -> \" + str(TotalCVs_Undefined/TotalCVs*100) + \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Exportación a JSON - MongoDB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El último paso del notebook almacenará toda la información obtenida en un repositorio de MongoDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymongo import MongoClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "myclient = MongoClient(\"mongodb://localhost:27017/\")\n",
    "mydb = myclient[\"candidates\"]\n",
    "mycol = mydb[\"CV\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pymongo.results.InsertManyResult at 0x108ff488>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mycol.insert_many(CVs_Dataframe.to_dict(\"records\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
